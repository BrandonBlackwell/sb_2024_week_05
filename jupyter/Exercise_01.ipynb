{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e3f68f-d9cb-46bf-8c06-ebcaf6aff821",
   "metadata": {},
   "source": [
    "# Exercise 01: SVD and Dimensionality Reduction\n",
    "\n",
    "In this exercise, you will explore a \"high-dimensional\" (D=5) dataset\n",
    "and determine:\n",
    "* whether or not a good low-dimensional representation exists\n",
    "* whether or not the data is linearly separable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce5a8a-aa3e-4560-a055-30da7f29bd03",
   "metadata": {},
   "source": [
    "As usual, let's start by installing and importing the stuff we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b04a7-1bb9-4c57-a42d-a3392e1c04bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U pip\n",
    "!{sys.executable} -m pip install -U scikit-learn matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0d6b31-32af-4320-87e6-266facbfdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb41aa9-326c-44bc-acd0-28924d07381c",
   "metadata": {},
   "source": [
    "Now we'll create some data to analyze.\n",
    "\n",
    "You don't need to understand this code in detail,\n",
    "but you might want to revisit it after you finish the exercise\n",
    "to see if you can figure out what I did and why I did it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e691a0f-a227-4826-930a-41d9cefbfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a 5D normal unit vector\n",
    "n = np.array([[0.5, 0.5, 0.5, 0.5, 0.5]]).T #np.random.rand(5,1)\n",
    "n_hat = n / np.linalg.norm(n)\n",
    "d = 10.0*np.random.rand(1,1)\n",
    "\n",
    "## create two unit vectors normal to n_hat\n",
    "a_1      = np.array([[0.5, -0.5, -0.5, -0.5, 0.5]]).T #np.random.rand(5,1)\n",
    "a_1_orth = a_1 - np.dot(n_hat.T, a_1)*n_hat\n",
    "a_1_hat  = a_1_orth / np.linalg.norm(a_1_orth)\n",
    "\n",
    "a_2            = np.array([[-0.5, 0.5, 0.5, 0.5, -0.5]]).T #np.random.rand(5,1)\n",
    "a_2_orth_1     = a_2 - np.dot(n_hat.T, a_2)*n_hat\n",
    "a_2_orth_2     = a_2_orth_1 - np.dot(a_1_hat.T, a_2_orth_1)*a_1_hat\n",
    "a_2_hat        = a_2_orth_2 / np.linalg.norm(a_2_orth_2)\n",
    "\n",
    "print('n_hat =\\n{}'.format(n_hat))\n",
    "print('a_1_hat =\\n{}'.format(a_1_hat))\n",
    "print('a_2_hat =\\n{}'.format(a_2_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2ce87-db25-4d87-bfa9-d461207d1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create clusters of random data\n",
    "np.random.seed(10)\n",
    "\n",
    "cluster_infos = [\n",
    "    ( 0.0, 0.0, 0.2, 1),\n",
    "    (+6.0, 0.0, 0.7, 2),\n",
    "    (-6.0, 0.0, 0.7, 3),\n",
    "    (+2.0,+2.0, 0.2, 4),\n",
    "    (+2.0,-2.0, 0.2, 5),\n",
    "    (-2.0,+2.0, 0.2, 6),\n",
    "    (-2.0,-2.0, 0.2, 7),\n",
    "]\n",
    "N_samples = 100\n",
    "\n",
    "coord_offset = np.array([[3.0, 0.0, -9.0, 4.0, 30.0]])\n",
    "\n",
    "all_samples = [];\n",
    "for (coord_1,coord_2,sigma,categ) in cluster_infos:\n",
    "    m = coord_1*a_1_hat + coord_2*a_2_hat\n",
    "    C = np.diagflat(sigma*sigma*np.ones((1,5)))\n",
    "    samples = np.random.default_rng().multivariate_normal(np.zeros((5,)), C, N_samples) + m.T + coord_offset;\n",
    "    samples = np.concatenate((samples,categ*np.ones((samples.shape[0],1))), axis=1)\n",
    "    all_samples.append(np.copy(samples))\n",
    "    \n",
    "samples = np.concatenate(all_samples, axis=0)\n",
    "sample_data = samples[:,0:5]\n",
    "sample_targets = samples[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9d50a-a27f-4804-95fa-12289de3b32b",
   "metadata": {},
   "source": [
    "Each row of `samples` contains one 5D data point and a classification category: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5a9e3-f9b8-440d-9647-cfc21ffb2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8249d03a-42cd-49fb-a386-d8030bb1f2a3",
   "metadata": {},
   "source": [
    "Let's convert `samples` to a pandas dataframe and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37830e-aef0-4552-a4d5-d168d64fc688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='ticks', color_codes=True)\n",
    "df = pd.DataFrame(\n",
    "    data=samples,\n",
    "    columns=['c_'+str(n) for n in range(5)] + ['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cdf94-8bc8-453f-8770-8747503cceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53fff2-29c8-44c1-80a7-c7b3cbd58dba",
   "metadata": {},
   "source": [
    "Time for some `pairplots`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fb4f8-b100-4aae-8b4a-c89c0269e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, hue='target');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa3e1e-bc1c-4918-9d8c-e9c91d09092d",
   "metadata": {},
   "source": [
    "**Based on the above plots, are the categories separable?  Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8860727f-c063-46df-8cc3-4edc90e9304b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f998aebc-9153-4a9f-9f81-2ea9f9883b44",
   "metadata": {},
   "source": [
    "Let's see if we can reduce the dimensionality of this data\n",
    "by applying Singular Value Decomposition (SVD)\n",
    "to its covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0127b-4041-4cfd-9bbd-3183430daaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = sample_data;\n",
    "CM = np.dot(M.T, M)\n",
    "U,S,Vh = np.linalg.svd(CM,full_matrices=True, compute_uv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9d3c8-f227-4688-b9ea-5909f81bd0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff6a5e-8eb8-4644-922f-93b62a897d82",
   "metadata": {},
   "source": [
    "**Based on the singular values in the `S` vector above,\n",
    "what's the smallest number of dimensions we can keep\n",
    "and still retain the vast majority of the data's information content?\n",
    "How did you arrive at that value?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47acdf7-9196-44fe-a688-d7998865ca32",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce082a8-df6b-4068-b0fa-1d2925b86561",
   "metadata": {},
   "source": [
    "Let's see what happens if we retain only 2 dimensions...\n",
    "\n",
    "We'll create a new matrix using the first 2 singular values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469cb4c-e432-441b-8270-3040130adfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(np.diagflat(S[0:2]), Vh[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e054057-a1e4-46fd-a193-24b99bfbc5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f204e3a7-bf3e-4c63-9a3b-96038cab9f26",
   "metadata": {},
   "source": [
    "**What is the shape of `P`?  What does that tell us about the effect `P` has on its inputs?  What does this matrix do for us?** (Hint: Why did I call it `P`?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6862798-f7e5-4002-b607-fd09efadc83a",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fbb94-3445-4d78-9917-891feeb76969",
   "metadata": {},
   "source": [
    "Let's apply `P` to our data and take a look at the 2D scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d26f4d-017e-4ef7-a220-18bc5464116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.dot(P,M.T)\n",
    "plt.scatter(new_data[0,:], new_data[1,:], c=samples[:,5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b61d44-50ff-41b2-bf16-f491ec74694a",
   "metadata": {},
   "source": [
    "**Based on the above plot, did our use of SVD significantly improve the separability of our data?  Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea059b-4c5c-477d-9b8c-4d5dc6df0fae",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c100f1e-2c40-4292-b74f-6819eb95da7d",
   "metadata": {},
   "source": [
    "Our original data wasn't centered at the origin nor were the axes scaled by their standard deviations.  Let's do that now and see if it impacts the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb2367-ff3e-4390-aaa9-2eaa671d7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(sample_data)\n",
    "scaled_sample_data = scaler.transform(sample_data)\n",
    "scaled_samples = np.concatenate((scaled_sample_data,samples[:,5:6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbb1c5-5545-4699-a9b4-dee9a3671d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = scaled_sample_data;\n",
    "CM = np.dot(M.T, M)\n",
    "U,S,Vh = np.linalg.svd(CM,full_matrices=True, compute_uv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6a686-accb-40b5-a834-663a13f25972",
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ecd3d-1a5f-4be1-9993-f7c13165f582",
   "metadata": {},
   "source": [
    "**Based on the singular values above, what is a reasonable estimate of the number of useful data dimensions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533915e-34e0-417c-8003-dc89a7534a0a",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf8c39-410f-43dd-babc-5d464a6c184c",
   "metadata": {},
   "source": [
    "Let's take a look at the new 2D scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1e9cf-f62e-4c30-a980-dd4e8da5d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(np.diagflat(S[0:2]), Vh[0:2,:])\n",
    "new_M = np.dot(P,M.T)\n",
    "plt.scatter(new_M[0,:], new_M[1,:], c=samples[:,5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125b1f3-eff5-4799-b986-686844d6392d",
   "metadata": {},
   "source": [
    "**Based on the above plot, is our data representable in 2D?  Is it separable in 2D?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e66040-4929-4626-9bf9-0769ee3deed2",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344914e-1f78-4691-b273-ad33eb13a2cb",
   "metadata": {},
   "source": [
    "**Why did data normalization have such a large impact on SVD?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e40c5-fc25-4f03-8db7-e5b5b554189c",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bca41be-c364-4722-86d6-045663911f5b",
   "metadata": {},
   "source": [
    "**Is this reduction from 5D to 2D lossy or lossless?** (Feel free to google those terms if you need to.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31615784-92a2-4d6d-8e96-1b0313d5d42d",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c790ed3f-0330-4b36-8fff-43b470c0956d",
   "metadata": {},
   "source": [
    "**Why would we want to reduce the dimensionality of our data? What advantages does it bring, if any?  What disadvantages?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5663619e-4de8-4a9a-9349-5f4fc7b8db72",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069adebd-7388-477c-aa01-b18b6ecec120",
   "metadata": {},
   "source": [
    "**What did you think of this exercise?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5935ae8-3ce2-409c-8fa7-9d9562a0fc90",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d6525-20ac-4362-8d3c-0bf31beebc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
