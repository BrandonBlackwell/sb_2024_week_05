{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fc57c7-3fb9-470a-b816-a0882e8695bb",
   "metadata": {},
   "source": [
    "# Exercise 02: SVD/PCA on MNIST Digits\n",
    "\n",
    "In this exercise,\n",
    "you'll explore the use of Singular Value Decomposition (SVD)\n",
    "to perform Principle Component Analysis (PCA)\n",
    "on the MNIST handwritten digits dataset.\n",
    "\n",
    "As usual, let's start by installing the needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e446eb3-05c0-4ef4-ab2a-b1b228877f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U pip\n",
    "!{sys.executable} -m pip install -U scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a807960-62e0-4c4f-9876-101574973749",
   "metadata": {},
   "source": [
    "Now let's load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2df5a-eecd-4640-92ce-9def4eec7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "dataset = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=20, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, dataset.images, dataset.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"%i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29666a9-1dbf-4f59-82b5-5aee14581d52",
   "metadata": {},
   "source": [
    "We have 1797 examples of 8x8 pixel images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351269e-2947-420a-a6e4-f12419510ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db27750-719d-4239-9511-3dc2a0b0734d",
   "metadata": {},
   "source": [
    "**How many dimensions does each image have?**\n",
    "\n",
    "(Hint #1: The answer isn't 2.)\n",
    "\n",
    "(Hint #2: How many numbers does it take to represent one image?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93caa989-5b98-4da0-9c9f-278c09380551",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef953e4-a81a-4f23-93d0-81a509b94181",
   "metadata": {},
   "source": [
    "We're going to \"flatten\" the 8x8 pixel images into 64 pixel vectors to aid our processing.\n",
    "Note the transpose (`.T`); each image vector is now a column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd059c-09db-489f-a225-28042129dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = len(dataset.images)\n",
    "data = dataset.images.reshape((N_samples, 64)).T\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7361bab3-37c4-4551-aefa-57f0f63bcbd5",
   "metadata": {},
   "source": [
    "Let's take a compare the tranpose of the first data vector\n",
    "(displayed as a row instead of a column)\n",
    "to the first 8x8 dataset image.\n",
    "Make sure you understand what you're looking at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff00517-4af1-411c-9fa8-d1cdc4909343",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data[:,0]=\\n{}'.format(data[:,0]))\n",
    "print('dataset.images[0]=\\n{}'.format(dataset.images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84882ea0-a490-4499-888f-b262eb2de74e",
   "metadata": {},
   "source": [
    "**Why do we need to normalize our data before performing SVD?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6fd59-53fb-41fc-882f-7d7981d6d960",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce08cc5-846d-4e6b-97c5-8421e7e83cbc",
   "metadata": {},
   "source": [
    "Let's go ahead and normalize.  We need to keep the mean and stddev info for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a6d6e-db06-4b9b-adaf-2cdc8eaa0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = np.mean(data, axis=1).reshape((64,1))\n",
    "#print('data_mean = \\n{}'.format(data_mean))\n",
    "\n",
    "data_stddev = np.std(data, axis=1).reshape((64,1))\n",
    "data_stddev[data_stddev == 0] = 0.001\n",
    "#print('data_stddev = \\n{}'.format(data_stddev))\n",
    "\n",
    "data_normalized = (data - data_mean)/data_stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c5a31-b933-4d39-ad09-145c8589354d",
   "metadata": {},
   "source": [
    "Inspect the following code and its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d8c72-4c11-469d-b046-0a82f32632ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(data_normalized, axis=1))\n",
    "print(np.std(data_normalized, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03be00e-3a53-4c20-8c05-cde25df4698f",
   "metadata": {},
   "source": [
    "**Do these values make sense?  Why or why not?  Do you see anything unexpected?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed6fb2-0cc1-4913-a3e5-357178d0ce8b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed433f0-5700-4f4b-81f8-e505fe56a0df",
   "metadata": {},
   "source": [
    "Now that we have normalized data,\n",
    "we can construct the covariance matrix.\n",
    "\n",
    "**What shape do you expect the covariance matrix to have?  Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef3b74-4ae6-4efa-a351-f0b6b1805e25",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d1456-61fe-4f23-9fe0-81c8e343fd9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = np.dot(data_normalized,data_normalized.T)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779b5f28-fcc9-4ecc-8b22-78489f46a4ed",
   "metadata": {},
   "source": [
    "Before you run the code below,\n",
    "stop and think about what we're doing:\n",
    "we want to reduce the dimensionality of the MNIST dataset\n",
    "to something more \"manageable\".\n",
    "\n",
    "**What is the minimum number of dimensions we can reasonably expect for this dataset?  Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d357a-af02-448d-ae9b-f4c05f224841",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc2acf-7527-456a-a430-a316a4c36e8c",
   "metadata": {},
   "source": [
    "Let's perform SVD on the covariance matrix,\n",
    "and inspect the diagonal, `S`, of the singular value matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b151510b-4ef0-42a2-a1d3-b9f1d822cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,Vh = np.linalg.svd(C)\n",
    "print('S = \\n{}'.format(S))\n",
    "plt.plot(S)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba442f-5dfd-4310-850e-72f2592970df",
   "metadata": {},
   "source": [
    "**Based on the values and scree plot above, how many meaningful dimensions does this MNIST data have?  How did you come to that conclusion?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656b0130-acc6-4c37-82e8-c63d7d3fe7c6",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665bda0-2aa5-4414-b5b2-f0a369a4eba2",
   "metadata": {},
   "source": [
    "**Based on the values and scree plot above, how many dimensions can we *definitely* get rid of?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa55fb9-b52b-48f4-a1a1-069da190449b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1469f3c-ae00-4cf9-b3ac-7128c251ac8e",
   "metadata": {},
   "source": [
    "**What do the dimensions we can eliminate say about the input data values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24fdd3c-e63c-4475-8cc9-efb12b2eb6f9",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b9e3cb-c8f3-4cde-9bb9-fd7572005a11",
   "metadata": {},
   "source": [
    "Below I've \"inverted\" the scree plot\n",
    "to show the percentage of information retained\n",
    "versus number of dimensions retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001f780-0b5f-4dc8-a246-210dcdbc2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(S)/np.sum(S))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e4ac9-5cd4-4bdb-a951-ef344c90c9d1",
   "metadata": {},
   "source": [
    "Let's retain only 5 dimensions and take a look at the results.\n",
    "\n",
    "First, we'll project our data onto the best 5D approximation of our covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09216d6f-b96b-4ce6-85e0-bf8d6dd41926",
   "metadata": {},
   "outputs": [],
   "source": [
    "ND = 5\n",
    "\n",
    "P = np.dot(np.diagflat(S[0:ND]), Vh[0:ND,:])\n",
    "compressed_data = np.dot(P,data_normalized)\n",
    "compressed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29512285-3e35-485b-acce-de3fff345445",
   "metadata": {},
   "source": [
    "**Explain the shape of `compressed_data` shown above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e8a52-38fd-412b-968e-78795382d984",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26d914-0385-40b6-af68-f5104ec57639",
   "metadata": {},
   "source": [
    "Our `compressed_data` currently lives in a 5D space with the basis determined by SVD.\n",
    "We'd like to bring it back into our original image space and coordinate system.\n",
    "\n",
    "Unfortunately, the matrix `P` is singular, so we can't invert it.\n",
    "Instead, we'll use the \"pseudo-inverse\" as the next best thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f61bb-0b41-46c8-9afb-752c9d191542",
   "metadata": {},
   "outputs": [],
   "source": [
    "UnP = np.linalg.pinv(P)\n",
    "UnP.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5107b11-3410-4f30-a62b-0a0dad1c6c6c",
   "metadata": {},
   "source": [
    "Now we'll use our \"unpack\" (`UnP`) matrix to bring our `compressed_data` back into the original input space.\n",
    "\n",
    "Note that we need to undo the data normalization, because that wasn't accounted for by the SVD process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997f118-ed4e-4e63-9801-df6c18cf8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpacked_data = np.dot(UnP,compressed_data)*data_stddev + data_mean\n",
    "unpacked_images = np.reshape(unpacked_data.T, (n_samples, 8, 8))\n",
    "unpacked_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da5ae0c-854d-4b0c-a9d0-d5f563315af4",
   "metadata": {},
   "source": [
    "Let's see how well 5 dimensions representated our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cd2c0-a510-459d-ac99-0e937f2028aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=20, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, unpacked_images, dataset.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"%i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf4812-1a36-4445-916f-37f82d2b697e",
   "metadata": {},
   "source": [
    "**What are your thoughts on these images?  Are 5 dimensions enough?  Why do some numbers appear reasonably clear while others are garbled?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc9a1b1-934f-4b8c-adac-c79a6d4758ca",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b7eb0-aa75-463c-aea3-8b5b61363cdf",
   "metadata": {},
   "source": [
    "Take a look at the first unpacked image values versus the original image values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594cf328-f718-4ac4-8aeb-925cd4c5eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unpacked_images[0] =\\n{}'.format(unpacked_images[0]))\n",
    "print('dataset.images[0] = \\n{}'.format(dataset.images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b508e6-2119-43d6-af65-4c761f7b72e1",
   "metadata": {},
   "source": [
    "Let's try the same steps again, but this time we'll retain all 64 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b041e9-21e2-4136-b060-6b1f8ed3bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ND = 64\n",
    "\n",
    "P = np.dot(np.diagflat(S[0:ND]), Vh[0:ND,:])\n",
    "compressed_data = np.dot(P,data_normalized)\n",
    "compressed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66767e21-106f-4185-87f1-26c221238c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "UnP = np.linalg.pinv(P)\n",
    "\n",
    "unpacked_data = np.dot(UnP,compressed_data)*data_stddev + data_mean\n",
    "unpacked_images = np.reshape(unpacked_data.T, (n_samples, 8, 8))\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=20, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, unpacked_images, dataset.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"%i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dbb686-ba4a-46bf-b5cb-c58ff3cf30bc",
   "metadata": {},
   "source": [
    "For comparison, let's look at the original dataset images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aaef8b-942f-4f08-946e-5f5e07ff454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=20, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, dataset.images, dataset.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"%i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37412914-ae1d-4d3c-8e85-b448b87a1839",
   "metadata": {},
   "source": [
    "**What do you notice?  Why is that the case?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350bd27-2602-4ffe-8dd9-22431eb1cd1b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e3595c-cbbd-4a68-b992-6660686f1c7d",
   "metadata": {},
   "source": [
    "Let's compare the unpacked/original image values again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7f295-c5c5-4550-b57e-cb0cdad757c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unpacked_images[0] =\\n{}'.format(unpacked_images[0]))\n",
    "print('dataset.images[0] = \\n{}'.format(dataset.images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9828c-aec8-4170-bd5b-167c4ba5e813",
   "metadata": {},
   "source": [
    "**How well did 64 dimensions approximate our original dataset?  Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d696f-051b-46f8-9384-d4d72ce8022b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac35a7-9e1e-4f8d-835e-33a5159ab89a",
   "metadata": {},
   "source": [
    "It would seem that there is some middle ground between 5D and 64D that would serve our purpose.  Let's try to find it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7819ce-778b-4f1f-92bc-cbfefd2c00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ND in range(4,65,4):    \n",
    "    P = np.dot(np.diagflat(S[0:ND]), Vh[0:ND,:])\n",
    "    compressed_data = np.dot(P,data_normalized)\n",
    "    UnP = np.linalg.pinv(P)\n",
    "\n",
    "    unpacked_data = np.dot(UnP,compressed_data)*data_stddev + data_mean\n",
    "    unpacked_images = np.reshape(unpacked_data.T, (n_samples, 8, 8))\n",
    "\n",
    "    _, axes = plt.subplots(nrows=1, ncols=20, figsize=(10, 3))\n",
    "    for ax, image, label in zip(axes, unpacked_images, dataset.target):\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "        ax.set_title(\"%i\" % ND)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84edf634-fe0b-44a7-b37e-fd4ea3dd016c",
   "metadata": {},
   "source": [
    "**Based on the above plots, how many dimensions would you retain?  How did you come to that conclusion?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b6fb4-abb9-4d86-98ed-5a6954462762",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb45ef-ba56-412d-bda4-2b2c80116bb9",
   "metadata": {},
   "source": [
    "**What did you think of this exercise?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbfc220-a85b-4c84-b78b-41d44fc62222",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a814e7-1ad3-4f5d-9524-7afeb3af3957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
